{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7dc0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7dec41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1    2    3    4    5         6         7         8         9  \\\n",
      "0  0.0  0.923388  0.0  0.0  0.0  0.0  2.990105  0.017291  1.682632  4.534331   \n",
      "1  0.0  1.929875  0.0  0.0  0.0  0.0  5.562883  0.777918  0.464271  5.591380   \n",
      "2  0.0  0.543871  0.0  0.0  0.0  0.0  3.117626  1.129129  0.000000  6.814785   \n",
      "3  0.0  2.290855  0.0  0.0  0.0  0.0  1.345732  0.800221  0.000000  6.536081   \n",
      "4  0.0  4.255888  0.0  0.0  0.0  0.0  0.000000  0.707398  0.000000  7.896858   \n",
      "\n",
      "   ...       119  120  121  122  123  124       125       126  127  NINO3.4  \n",
      "0  ...  0.155618  0.0  0.0  0.0  0.0  0.0  6.695034  1.521119  0.0    -1.55  \n",
      "1  ...  1.411000  0.0  0.0  0.0  0.0  0.0  6.529056  2.613518  0.0    -1.78  \n",
      "2  ...  1.029515  0.0  0.0  0.0  0.0  0.0  5.309260  2.167389  0.0    -1.38  \n",
      "3  ...  1.345663  0.0  0.0  0.0  0.0  0.0  4.031511  2.411777  0.0    -1.90  \n",
      "4  ...  2.738996  0.0  0.0  0.0  0.0  0.0  1.775552  4.273332  0.0    -1.74  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(r'C:\\Users\\kettin\\Documents\\Lomba\\GEMASTIKSciPaper\\Dataset\\ENSO_dataset_balanced.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f674e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisasi selesai. Fitur sekarang 0–1, target tetap asli.\n",
      "Ukuran dataset: 1221 sampel, 128 fitur + 1 target (NINO3.4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Pisahkan fitur dan target dari df\n",
    "X = df.drop(columns=['NINO3.4']).values  # semua kolom kecuali target\n",
    "y = df['NINO3.4'].values  # target tetap apa adanya\n",
    "\n",
    "# Normalisasi ulang fitur\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Gabung kembali jadi DataFrame\n",
    "df = pd.DataFrame(X_scaled, columns=df.columns[:-1])  # fitur dengan nama kolom aslinya\n",
    "df['NINO3.4'] = y  # target tetap sama (nggak dinormalisasi)\n",
    "\n",
    "print(\"Normalisasi selesai. Fitur sekarang 0–1, target tetap asli.\")\n",
    "print(f\"Ukuran dataset: {df.shape[0]} sampel, {df.shape[1]-1} fitur + 1 target (NINO3.4)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbd6893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1    2    3    4    5         6         7         8         9  \\\n",
      "0  0.0  0.088295  0.0  0.0  0.0  0.0  0.227698  0.001255  0.197671  0.335540   \n",
      "1  0.0  0.184535  0.0  0.0  0.0  0.0  0.423616  0.056479  0.054541  0.413761   \n",
      "2  0.0  0.052005  0.0  0.0  0.0  0.0  0.237408  0.081978  0.000000  0.504293   \n",
      "3  0.0  0.219052  0.0  0.0  0.0  0.0  0.102478  0.058099  0.000000  0.483669   \n",
      "4  0.0  0.406950  0.0  0.0  0.0  0.0  0.000000  0.051359  0.000000  0.584366   \n",
      "\n",
      "   ...       119  120  121  122  123  124       125       126  127  NINO3.4  \n",
      "0  ...  0.010775  0.0  0.0  0.0  0.0  0.0  0.557715  0.144249  0.0    -1.55  \n",
      "1  ...  0.097702  0.0  0.0  0.0  0.0  0.0  0.543889  0.247843  0.0    -1.78  \n",
      "2  ...  0.071287  0.0  0.0  0.0  0.0  0.0  0.442276  0.205536  0.0    -1.38  \n",
      "3  ...  0.093177  0.0  0.0  0.0  0.0  0.0  0.335836  0.228711  0.0    -1.90  \n",
      "4  ...  0.189656  0.0  0.0  0.0  0.0  0.0  0.147909  0.405245  0.0    -1.74  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dca5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce26e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 96\n",
    "prediction_length = 24\n",
    "stride = 12  # window geser 12 bulan\n",
    "\n",
    "class ENSODataset(Dataset):\n",
    "    def __init__(self, df, context_length, prediction_length, stride=1):\n",
    "        self.features = df.drop(columns=[\"NINO3.4\"]).values.astype(np.float32)\n",
    "        self.target = df[\"NINO3.4\"].values.astype(np.float32)\n",
    "        self.context_length = context_length\n",
    "        self.prediction_length = prediction_length\n",
    "        self.stride = stride\n",
    "        self.indices = self.create_indices()\n",
    "\n",
    "    def create_indices(self):\n",
    "        total_length = self.context_length + self.prediction_length\n",
    "        return [\n",
    "            i for i in range(0, len(self.target) - total_length, self.stride)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.indices[idx]\n",
    "        past_values = self.target[i : i + self.context_length]\n",
    "        future_values = self.target[i + self.context_length : i + self.context_length + self.prediction_length]\n",
    "\n",
    "        past_time_features = self.features[i : i + self.context_length]\n",
    "        future_time_features = self.features[i + self.context_length : i + self.context_length + self.prediction_length]\n",
    "\n",
    "        return {\n",
    "            \"past_values\": torch.tensor(past_values).unsqueeze(-1),\n",
    "            \"past_time_features\": torch.tensor(past_time_features),\n",
    "            \"future_time_features\": torch.tensor(future_time_features),\n",
    "            \"future_values\": torch.tensor(future_values).unsqueeze(-1),\n",
    "            \"past_observed_mask\": torch.ones_like(torch.tensor(past_values)).unsqueeze(-1),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd9b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "df_train = df.iloc[:train_size]\n",
    "df_test = df.iloc[train_size:]\n",
    "\n",
    "train_dataset = ENSODataset(df_train, context_length, prediction_length, stride)\n",
    "test_dataset = ENSODataset(df_test, context_length, prediction_length, stride)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ae1d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TimeSeriesTransformerConfig(\n",
    "    prediction_length=prediction_length,\n",
    "    context_length=context_length,\n",
    "    lags_sequence=[1],\n",
    "    input_size=1,\n",
    "    num_time_features=128,  # sesuai jumlah kolom fitur kamu\n",
    "    num_static_categorical_features=0,\n",
    "    d_model=64,\n",
    "    encoder_layers=3,\n",
    "    decoder_layers=3,\n",
    ")\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a41f3a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "lags cannot go further than history length, found lag 1 while history length is only 120",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m     12\u001b[0m     batch[k] \u001b[38;5;241m=\u001b[39m batch[k]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output\u001b[38;5;241m.\u001b[39mloss, torch\u001b[38;5;241m.\u001b[39mzeros_like(output\u001b[38;5;241m.\u001b[39mloss))  \u001b[38;5;66;03m# loss sudah dihitung di dalam model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1680\u001b[0m, in \u001b[0;36mTimeSeriesTransformerForPrediction.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, future_observed_mask, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1678\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1680\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1699\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1701\u001b[0m prediction_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1395\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1392\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   1393\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1395\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1406\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1224\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[1;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;66;03m# lagged features\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m subsequences_length \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_length\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length\n\u001b[0;32m   1223\u001b[0m )\n\u001b[1;32m-> 1224\u001b[0m lagged_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lagged_subsequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsequences_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubsequences_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1225\u001b[0m lags_shape \u001b[38;5;241m=\u001b[39m lagged_sequence\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1226\u001b[0m reshaped_lagged_sequence \u001b[38;5;241m=\u001b[39m lagged_sequence\u001b[38;5;241m.\u001b[39mreshape(lags_shape[\u001b[38;5;241m0\u001b[39m], lags_shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1148\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.get_lagged_subsequences\u001b[1;34m(self, sequence, subsequences_length, shift)\u001b[0m\n\u001b[0;32m   1145\u001b[0m indices \u001b[38;5;241m=\u001b[39m [lag \u001b[38;5;241m-\u001b[39m shift \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlags_sequence]\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(indices) \u001b[38;5;241m+\u001b[39m subsequences_length \u001b[38;5;241m>\u001b[39m sequence_length:\n\u001b[1;32m-> 1148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlags cannot go further than history length, found lag \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1150\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile history length is only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1151\u001b[0m     )\n\u001b[0;32m   1153\u001b[0m lagged_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag_index \u001b[38;5;129;01min\u001b[39;00m indices:\n",
      "\u001b[1;31mValueError\u001b[0m: lags cannot go further than history length, found lag 1 while history length is only 120"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        for k in batch:\n",
    "            batch[k] = batch[k].to(device)\n",
    "        output = model(**batch)\n",
    "        loss = loss_fn(output.loss, torch.zeros_like(output.loss))  # loss sudah dihitung di dalam model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
