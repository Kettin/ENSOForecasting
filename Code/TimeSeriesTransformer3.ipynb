{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7dc0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7dec41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1    2    3    4    5         6         7         8         9  \\\n",
      "0  0.0  0.923388  0.0  0.0  0.0  0.0  2.990105  0.017291  1.682632  4.534331   \n",
      "1  0.0  1.929875  0.0  0.0  0.0  0.0  5.562883  0.777918  0.464271  5.591380   \n",
      "2  0.0  0.543871  0.0  0.0  0.0  0.0  3.117626  1.129129  0.000000  6.814785   \n",
      "3  0.0  2.290855  0.0  0.0  0.0  0.0  1.345732  0.800221  0.000000  6.536081   \n",
      "4  0.0  4.255888  0.0  0.0  0.0  0.0  0.000000  0.707398  0.000000  7.896858   \n",
      "\n",
      "   ...       119  120  121  122  123  124       125       126  127  NINO3.4  \n",
      "0  ...  0.155618  0.0  0.0  0.0  0.0  0.0  6.695034  1.521119  0.0    -1.55  \n",
      "1  ...  1.411000  0.0  0.0  0.0  0.0  0.0  6.529056  2.613518  0.0    -1.78  \n",
      "2  ...  1.029515  0.0  0.0  0.0  0.0  0.0  5.309260  2.167389  0.0    -1.38  \n",
      "3  ...  1.345663  0.0  0.0  0.0  0.0  0.0  4.031511  2.411777  0.0    -1.90  \n",
      "4  ...  2.738996  0.0  0.0  0.0  0.0  0.0  1.775552  4.273332  0.0    -1.74  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(r'C:\\Users\\kettin\\Documents\\Lomba\\GEMASTIKSciPaper\\Dataset\\ENSO_dataset_balanced.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f674e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisasi selesai. Fitur sekarang 0–1, target tetap asli.\n",
      "Ukuran dataset: 1221 sampel, 128 fitur + 1 target (NINO3.4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Pisahkan fitur dan target dari df\n",
    "X = df.drop(columns=['NINO3.4']).values  # semua kolom kecuali target\n",
    "y = df['NINO3.4'].values  # target tetap apa adanya\n",
    "\n",
    "# Normalisasi ulang fitur\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Gabung kembali jadi DataFrame\n",
    "df = pd.DataFrame(X_scaled, columns=df.columns[:-1])  # fitur dengan nama kolom aslinya\n",
    "df['NINO3.4'] = y  # target tetap sama (nggak dinormalisasi)\n",
    "\n",
    "print(\"Normalisasi selesai. Fitur sekarang 0–1, target tetap asli.\")\n",
    "print(f\"Ukuran dataset: {df.shape[0]} sampel, {df.shape[1]-1} fitur + 1 target (NINO3.4)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bbd6893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1    2    3    4    5         6         7         8         9  \\\n",
      "0  0.0  0.088295  0.0  0.0  0.0  0.0  0.227698  0.001255  0.197671  0.335540   \n",
      "1  0.0  0.184535  0.0  0.0  0.0  0.0  0.423616  0.056479  0.054541  0.413761   \n",
      "2  0.0  0.052005  0.0  0.0  0.0  0.0  0.237408  0.081978  0.000000  0.504293   \n",
      "3  0.0  0.219052  0.0  0.0  0.0  0.0  0.102478  0.058099  0.000000  0.483669   \n",
      "4  0.0  0.406950  0.0  0.0  0.0  0.0  0.000000  0.051359  0.000000  0.584366   \n",
      "\n",
      "   ...       119  120  121  122  123  124       125       126  127  NINO3.4  \n",
      "0  ...  0.010775  0.0  0.0  0.0  0.0  0.0  0.557715  0.144249  0.0    -1.55  \n",
      "1  ...  0.097702  0.0  0.0  0.0  0.0  0.0  0.543889  0.247843  0.0    -1.78  \n",
      "2  ...  0.071287  0.0  0.0  0.0  0.0  0.0  0.442276  0.205536  0.0    -1.38  \n",
      "3  ...  0.093177  0.0  0.0  0.0  0.0  0.0  0.335836  0.228711  0.0    -1.90  \n",
      "4  ...  0.189656  0.0  0.0  0.0  0.0  0.0  0.147909  0.405245  0.0    -1.74  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4035ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import TimeSeriesTransformerForPrediction, TimeSeriesTransformerConfig\n",
    "\n",
    "# Gunakan hanya kolom target\n",
    "target_series = df['NINO3.4'].values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26976c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 120  # 10 tahun konteks\n",
    "prediction_length = 24  # 2 tahun ke depan\n",
    "stride = 12  # geser setahun sekali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f2f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENSOUnivariateDataset(Dataset):\n",
    "    def __init__(self, series, context_length, prediction_length, stride=1):\n",
    "        self.series = series\n",
    "        self.context_length = context_length\n",
    "        self.prediction_length = prediction_length\n",
    "        self.stride = stride\n",
    "        self.indices = self.create_indices()\n",
    "\n",
    "    def create_indices(self):\n",
    "        total = self.context_length + self.prediction_length\n",
    "        return [i for i in range(0, len(self.series) - total, self.stride)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.indices[idx]\n",
    "        past_values = self.series[i : i + self.context_length]\n",
    "        future_values = self.series[i + self.context_length : i + self.context_length + self.prediction_length]\n",
    "        return {\n",
    "            \"past_values\": torch.tensor(past_values).unsqueeze(-1),  # (context_length, 1)\n",
    "            \"future_values\": torch.tensor(future_values).unsqueeze(-1),\n",
    "            \"past_observed_mask\": torch.ones(self.context_length, 1),  # all observed\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39e35195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kettin\\.cache\\huggingface\\hub\\models--huggingface--time-series-transformer-tourism-monthly. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerForPrediction(\n",
       "  (model): TimeSeriesTransformerModel(\n",
       "    (scaler): TimeSeriesMeanScaler()\n",
       "    (embedder): TimeSeriesFeatureEmbedder(\n",
       "      (embedders): ModuleList(\n",
       "        (0): Embedding(366, 6)\n",
       "      )\n",
       "    )\n",
       "    (encoder): TimeSeriesTransformerEncoder(\n",
       "      (value_embedding): TimeSeriesValueEmbedding(\n",
       "        (value_projection): Linear(in_features=27, out_features=26, bias=False)\n",
       "      )\n",
       "      (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(48, 26)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TimeSeriesTransformerEncoderLayer(\n",
       "          (self_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (v_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (q_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (out_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=26, out_features=32, bias=True)\n",
       "          (fc2): Linear(in_features=32, out_features=26, bias=True)\n",
       "          (final_layer_norm): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TimeSeriesTransformerDecoder(\n",
       "      (value_embedding): TimeSeriesValueEmbedding(\n",
       "        (value_projection): Linear(in_features=27, out_features=26, bias=False)\n",
       "      )\n",
       "      (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(48, 26)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TimeSeriesTransformerDecoderLayer(\n",
       "          (self_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (v_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (q_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (out_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (v_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (q_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "            (out_proj): Linear(in_features=26, out_features=26, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=26, out_features=32, bias=True)\n",
       "          (fc2): Linear(in_features=32, out_features=26, bias=True)\n",
       "          (final_layer_norm): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (parameter_projection): ParameterProjection(\n",
       "    (proj): ModuleList(\n",
       "      (0-2): 3 x Linear(in_features=26, out_features=1, bias=True)\n",
       "    )\n",
       "    (domain_map): LambdaLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TimeSeriesTransformerForPrediction.from_pretrained(\"huggingface/time-series-transformer-tourism-monthly\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a758d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(target_series) * 0.8)\n",
    "train_series = target_series[:train_size]\n",
    "test_series = target_series[train_size:]\n",
    "\n",
    "test_dataset = ENSOUnivariateDataset(test_series, context_length, prediction_length, stride)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9da1bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TimeSeriesTransformerForPrediction.forward() missing 1 required positional argument: 'past_time_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m      7\u001b[0m     batch[key] \u001b[38;5;241m=\u001b[39m batch[key]\n\u001b[1;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m      9\u001b[0m mean_prediction \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     10\u001b[0m target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kettin\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mTypeError\u001b[0m: TimeSeriesTransformerForPrediction.forward() missing 1 required positional argument: 'past_time_features'"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        for key in batch:\n",
    "            batch[key] = batch[key]\n",
    "        output = model(**batch)\n",
    "        mean_prediction = output.distributions.mean.squeeze().numpy()\n",
    "        target = batch[\"future_values\"].squeeze().numpy()\n",
    "        predictions.append(mean_prediction)\n",
    "        targets.append(target)\n",
    "\n",
    "y_pred = np.concatenate(predictions)\n",
    "y_true = np.concatenate(targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
