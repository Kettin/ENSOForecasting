{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd4de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44159306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feat_0  feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
      "0  1950.0     1.0 -1.143366 -1.265137 -1.278335 -1.175420 -0.921329 -0.604104   \n",
      "1  1950.0     2.0 -1.044837 -1.166932 -1.236573 -1.226775 -1.104201 -0.925912   \n",
      "2  1950.0     3.0 -1.623563 -1.796104 -1.800000 -1.800000 -1.727419 -1.591487   \n",
      "3  1950.0     4.0 -1.800000 -1.800000 -1.800000 -1.800000 -1.800000 -1.800000   \n",
      "4  1950.0     5.0 -1.800000 -1.800000 -1.800000 -1.800000 -1.800000 -1.800000   \n",
      "\n",
      "     feat_8    feat_9  ...  feat_10981  feat_10982  feat_10983  feat_10984  \\\n",
      "0 -0.486660 -0.482734  ...        -1.8        -1.8        -1.8        -1.8   \n",
      "1 -0.857395 -0.853803  ...        -1.8        -1.8        -1.8        -1.8   \n",
      "2 -1.554991 -1.570794  ...        -1.8        -1.8        -1.8        -1.8   \n",
      "3 -1.800000 -1.800000  ...        -1.8        -1.8        -1.8        -1.8   \n",
      "4 -1.800000 -1.800000  ...        -1.8        -1.8        -1.8        -1.8   \n",
      "\n",
      "   feat_10985  feat_10986  feat_10987  feat_10988  feat_10989  NINO3.4  \n",
      "0        -1.8        -1.8        -1.8        -1.8        -1.8    24.55  \n",
      "1        -1.8        -1.8        -1.8        -1.8        -1.8    25.06  \n",
      "2        -1.8        -1.8        -1.8        -1.8        -1.8    25.87  \n",
      "3        -1.8        -1.8        -1.8        -1.8        -1.8    26.28  \n",
      "4        -1.8        -1.8        -1.8        -1.8        -1.8    26.18  \n",
      "\n",
      "[5 rows x 10991 columns]\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(r'C:\\Users\\kettin\\Documents\\Lomba\\GEMASTIKSciPaper\\Dataset\\ENSO_dataset_balanced_transformer2.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb1b18a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rentang nilai data: min = -1.7999999523162842, max = 2024.0\n",
      "Jumlah baris dengan nilai di luar 0–1: 1232\n"
     ]
    }
   ],
   "source": [
    "# Cari nilai minimum dan maksimum dari seluruh dataset\n",
    "min_val = df.min().min()\n",
    "max_val = df.max().max()\n",
    "\n",
    "print(f\"Rentang nilai data: min = {min_val}, max = {max_val}\")\n",
    "\n",
    "# Cek kolom mana saja yang ada di luar 0–1 (kalau ada)\n",
    "out_of_range = df[(df < 0).any(axis=1) | (df > 1).any(axis=1)]\n",
    "print(f\"Jumlah baris dengan nilai di luar 0–1: {len(out_of_range)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1505dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rentang nilai data: min = 0.0 max = 1.0000000000000018\n",
      "   feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
      "0     0.0  0.000000  0.502718  0.447368  0.454277  0.507343  0.571510   \n",
      "1     0.0  0.090909  0.578152  0.529509  0.490645  0.465627  0.452565   \n",
      "2     0.0  0.181818  0.135080  0.003259  0.000000  0.000000  0.047208   \n",
      "3     0.0  0.272727  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4     0.0  0.363636  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "     feat_7    feat_8    feat_9  ...  feat_10981  feat_10982  feat_10983  \\\n",
      "0  0.646229  0.670085  0.681569  ...         0.0         0.0         0.0   \n",
      "1  0.472333  0.480931  0.489573  ...         0.0         0.0         0.0   \n",
      "2  0.112675  0.125007  0.118594  ...         0.0         0.0         0.0   \n",
      "3  0.000000  0.000000  0.000000  ...         0.0         0.0         0.0   \n",
      "4  0.000000  0.000000  0.000000  ...         0.0         0.0         0.0   \n",
      "\n",
      "   feat_10984  feat_10985  feat_10986  feat_10987  feat_10988  feat_10989  \\\n",
      "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "    NINO3.4  \n",
      "0  0.058027  \n",
      "1  0.156673  \n",
      "2  0.313346  \n",
      "3  0.392650  \n",
      "4  0.373308  \n",
      "\n",
      "[5 rows x 10991 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# df adalah dataset hasil ADASYN\n",
    "scaler_final = MinMaxScaler()\n",
    "\n",
    "# Normalisasi semua kolom\n",
    "df_scaled_final = pd.DataFrame(\n",
    "    scaler_final.fit_transform(df),\n",
    "    columns=df.columns\n",
    ")\n",
    "\n",
    "# Cek ulang rentang nilai\n",
    "print(\"Rentang nilai data:\",\n",
    "      f\"min = {df_scaled_final.min().min()}\",\n",
    "      f\"max = {df_scaled_final.max().max()}\")\n",
    "print(df_scaled_final.head())\n",
    "df_scaled_final = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d26185aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (680, 18, 10990) Val shape: (292, 18, 10990) Test shape: (243, 18, 10990)\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 464ms/step - loss: 66049.8359 - root_mean_squared_error: 245.1178 - val_loss: 93.6284 - val_root_mean_squared_error: 9.6762 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - loss: 928.6312 - root_mean_squared_error: 30.2239 - val_loss: 57.2464 - val_root_mean_squared_error: 7.5661 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 392ms/step - loss: 140.4532 - root_mean_squared_error: 11.7276 - val_loss: 38.1830 - val_root_mean_squared_error: 6.1792 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 389ms/step - loss: 47.6301 - root_mean_squared_error: 6.8976 - val_loss: 9.2148 - val_root_mean_squared_error: 3.0356 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 386ms/step - loss: 52.3664 - root_mean_squared_error: 7.2319 - val_loss: 1.3588 - val_root_mean_squared_error: 1.1657 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - loss: 46.1418 - root_mean_squared_error: 6.7917 - val_loss: 10.4520 - val_root_mean_squared_error: 3.2330 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - loss: 35.9550 - root_mean_squared_error: 5.9782 - val_loss: 24.2159 - val_root_mean_squared_error: 4.9210 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - loss: 35.9830 - root_mean_squared_error: 5.9952 - val_loss: 23.1422 - val_root_mean_squared_error: 4.8106 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - loss: 39.3386 - root_mean_squared_error: 6.2695 - val_loss: 38.1295 - val_root_mean_squared_error: 6.1749 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - loss: 45.2886 - root_mean_squared_error: 6.7198 - val_loss: 1.4449 - val_root_mean_squared_error: 1.2020 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - loss: 45.5331 - root_mean_squared_error: 6.7354 - val_loss: 1.6127 - val_root_mean_squared_error: 1.2699 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - loss: 40.1065 - root_mean_squared_error: 6.3319 - val_loss: 1.4515 - val_root_mean_squared_error: 1.2048 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - loss: 50.0011 - root_mean_squared_error: 7.0693 - val_loss: 1.5230 - val_root_mean_squared_error: 1.2341 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - loss: 42.2317 - root_mean_squared_error: 6.4970 - val_loss: 1.4740 - val_root_mean_squared_error: 1.2141 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - loss: 38.5266 - root_mean_squared_error: 6.2004 - val_loss: 1.7280 - val_root_mean_squared_error: 1.3145 - learning_rate: 5.0000e-04\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001376E790310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n",
      "Test RMSE: 0.7659\n",
      "Test NRMSE: 0.2278\n",
      "Test R²: -0.8950\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# --- Data Preparation ---\n",
    "X = df_scaled_final.drop(columns=['NINO3.4']).values\n",
    "y = df_scaled_final['NINO3.4'].values\n",
    "\n",
    "def create_sequences(X, y, window_size=24):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - window_size + 1):\n",
    "        X_seq.append(X[i:i+window_size])\n",
    "        y_seq.append(y[i+window_size-1])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "window_size = 18\n",
    "X_seq, y_seq = create_sequences(X, y, window_size)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, shuffle=False)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Val shape:\", X_val.shape, \"Test shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "# --- Transformer Model with Projection Fix ---\n",
    "def build_transformer(input_shape, head_size=64, num_heads=2, ff_dim=64, num_transformer_blocks=2, mlp_units=[64], dropout=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        # Normalization + Multi-Head Attention\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(x1, x1)\n",
    "        x2 = layers.Add()([x, attention])\n",
    "\n",
    "        # Feed-Forward Block (dimensi disesuaikan)\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        ff = layers.Dense(ff_dim, activation=\"relu\")(x3)\n",
    "        ff = layers.Dropout(dropout)(ff)\n",
    "\n",
    "        # Proyeksikan x2 agar match dengan ff\n",
    "        proj_x2 = layers.Dense(ff_dim)(x2)\n",
    "        x = layers.Add()([proj_x2, ff])  # dimensi sudah sama\n",
    "\n",
    "    # Global Pooling + Output\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    for units in mlp_units:\n",
    "        x = layers.Dense(units, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)  # regresi output\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Build & Compile Model\n",
    "model = build_transformer(input_shape=X_train.shape[1:])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=5e-4)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "nrmse = rmse / (y_test.max() - y_test.min())\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test NRMSE: {nrmse:.4f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
